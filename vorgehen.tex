\section{Projektplanung}
\label{sec:project_plan}
Abbildung \ref{fig:workpackages} zeigt die Aufteilung Masterthesis in einzelne Arbeitspakete. Das Ziel der Einarbeitungsphase ist ein grundlegendes Verständnis über die Datenverarbeitung im Hadoop-Framework zu erhalten. Zusätzlich soll eine Entwicklungsumgebung inklusive öffentlicher Versionsverwaltung eingerichtet werden. Darauf erfolgt der Aufbau eines eigenen Hadoop-Clusters und die Beschaffung von Testdaten.\footnote{Auch ein Zugriff auf einen bestehendes Hadoop-Cluster ist möglich.} Für die Einarbeitung und den Aufbau sind vier Wochen eingeplant (siehe Abbildung \ref{fig:ganttA}).\footnote{Die referenzierten Gantt-Diagramme wurden mit der JavaScript-Bibliothek \textit{dhtmlxGantt} erstellt. Der Quellcode ist unter der \textit{GNU GPLv2}-Lizenz lizenziert. Weiter Informationen können in Kapitel \ref{sec:licencing_issues} im Anhang nachgelesen werden.}\\

\noindent
Der zweite Teil behandelt die Rohdatenspeicherung im HDFS und eine Datenaufbereitung. Es soll geprüft werden, welche Struktur der Daten für eine optimale Speicherung und Verarbeitung im Hadoop-Framework erforderlich ist. Dieser Teil beansprucht abermals vier Wochen. Am Ende dieses Arbeitspaketes soll ein erster Zwischenbericht erstellt werden, welcher die bisherigen Ergebnisse enthält (sieh Abbildung \ref{fig:ganttA}).\\

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{./resource/Arbeitspakete.pdf}
  \caption{Arbeitspakete der Masterthesis}
  \label{fig:workpackages}
\end{figure}

\noindent
Nach der Speicherung der Rohdaten erfolgt im dritten Arbeitspaket die Datenanalyse mit Apache Spark. Hier sollen die Daten nach anwendungsbezogenen Problemstellungen analysiert werden. Das Ergebnis ist eine Sammlung von Programmen, welche mit Apache Spark auf den Daten ausgeführt werden können. Darüber hinaus soll ermittelt werden, welche Möglichkeiten zur Ausführung dieser Spark-Anwendungen bestehen.\footnote{Hier könnte beispielsweise das Projekt Apache Livy nützlich sein.} Ein weiterer Aspekt der Datenanalyse beschäftigt sich mit den Möglichkeiten, wie die Ergebnisse persistiert werden können.\footnote{Hier könnten die
Projekte Apache Hive und Apache HBase zur Speicherung von strukturierten und unstrukturierten Daten untersucht werden.} Im Anschluss soll die Performanz der Algorithmen geprüft werden. Hier bietet sich der Vergleich zu herkömmlichen Analyseprogrammen an. Denn schließlich hat diese Thesis auch das Ziel, bei großen Datenmengen schneller Ergebnisse zu liefern als die herkömmlichen Analysewerkzeuge auf einem einzelnen Analyserechner. Für dieses Arbeitspaket sind sieben Wochen eingeplant (siehe Abbildung \ref{fig:ganttB}). Darauf folgt ein zweiter Zwischenbericht.\\

\noindent
Im letzten Drittel der Masterthesis sollen die querschnittlichen Aspekte in der bestehenden Datenverarbeitung berücksichtigt werden. Hierbei geht es um das Absichern der Analyseplattform, die Dokumentation der Chain of Custody und das Löschen von nicht mehr verwendeten personenbezogenen Daten. Für dieses Arbeitspaket sind vier Wochen eingeplant (siehe Abbildung \ref{fig:ganttC}).\\

\noindent
Das letzte Arbeitspaket enthält ein prototypische Visualisierung der Analyseergebnisse. Hierbei soll geprüft werden, welche Möglichkeiten zur Darstellung der Ergebnisse existieren. Der Forensiker soll auf möglichst einfache Art und Weise die Ergebnisse ansehen können. Für diese Arbeit sind drei Wochen eingeplant (siehe Abbildung \ref{fig:ganttC}).\\

\begin{figure}[p]
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{./resource/ganttA.png}
  \caption{Projektplan Teil A - Einarbeitung und Rohdatenspeicherung (siehe Kapitel \ref{sec:licencing_issues})}
  \label{fig:ganttA}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{./resource/ganttB.png}
  \caption{Projektplan Teil B - Datenanalyse (siehe Kapitel \ref{sec:licencing_issues})}
  \label{fig:ganttB}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{./resource/ganttC.png}
  \caption{Projektplan Teil C - Querschnittliche Aspekte und Visualisierung (siehe Kapitel \ref{sec:licencing_issues})}
  \label{fig:ganttC}
\end{figure}

\clearpage
\section{Entwicklungsumgebung}
\label{development_environment}
Der Aufbau eine Test- und Entwicklungsumgebung ist ein wichtiger Bestandteil dieser Thesis. Einerseits sollen Anwendungsprogramme zur Datenverarbeitung schnell und lokal ausführbar sein. Andererseits soll die Testumgebung auf einem physikalischem Apache Hadoop Cluster basieren, um mögliche Infrastrukturprobleme identifizieren zu können und die Performanz zu testen. \\

TODO: InelliJ Idea + Kotlin aufnehmen!

\noindent
Abbildung \ref{fig:development_environment} skizziert die Komponenten der Entwicklungsumgebung. Zentraler Bestandteil ist ein Entwicklungsrechner mit der Linux-Distribution \textit{Fedora} in der Version 27 64-bit.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{./resource/development_environment.pdf}
  \caption{Komponenten der Entwicklungsumgebung}
  \label{fig:development_environment}
\end{figure} 

\noindent
Zur Entwicklung der forensischen Analyseprogramme wird \textit{Eclipse Oxygen} genutzt. Die Anwendungen selbst werden in Java geschrieben.\footnote{Wobei auch Python oder Scala als Programmiersprache genutzt werden kann.} Zum Bauen der ausführbaren Java-Archive (JAR-Dateien) wird \textit{Maven} verwendet. Mit Maven können weitere Java-Bibliotheken 
in eigenen Programmen auf einfache Weise wiederverwendet werden.\footnote{Diese können über ein zentrales Repository, dem sogenannten \textit{Maven Central Repository} aus dem Internet geladen werden (siehe \url{https://search.maven.org/}).}\\
Um die gebauten Java-Programme zur Datenanalyse schnell testen zu können, kann auf dem lokalen Entwicklungsrechner eine Apache Spark Standalone Instanz gestartet werden. Diese dient ausschließlich zur simplen Ausführung von Spark-Applikationen. Hierbei arbeitet die Instanz direkt auf dem lokalen Dateisystem und nutzt kein HDFS. Darüber hinaus wird nicht YARN, sondern ein bei Apache Spark mitgelieferter Ressourcenmanager genutzt.\footnote{Siehe Kapitel \ref{ch:theory_hadoop} für eine detaillierte Erklärung von Apache Hadoop.}\\

\noindent
Analog zur Spark Standalone Instanz kann auch ein Hadoop Pseudo-Distributed Single Node auf dem lokalen Rechner gestartet werden.\footnote{Hierfür muss der Entwicklungsrechner entsprechende Ressourcen bereitstellen. Es sollten mindestens eine Quad-Core-CPU, 16 GB Arbeitsspeicher und eine SSD zur Verfügung stehen, um halbwegs performant arbeiten zu können.} Mithilfe diese Single-Nodes können spezifische Konfiguration des HDFS oder des Ressourcenmanagers YARN ausprobiert werden.\\
Letztendlich kommen diese lokale Hadoop und Spark Instanzen aber schnell an ihre Grenzen. Daher werden spezifische Konfigurationen und fertiggestellte Analyseprogramme auch auf einem realen
Apache Hadoop Test-Cluster durchgeführt. Dort kann das Zusammenspiel zwischen Hadoop und Spark nachvollzogen werden. Auch entsprechende Last- und Performance-Tests sind nur auf dem Hadoop Test-Cluster sinnvoll.\\
Um mit dem Test-Cluster arbeiten zu können, wird ein SSH-Client benötigt. Zusätzliche gibt es auch eine Web-Oberfläche basierend auf Apache Ambari zur Konfiguration und Anzeige des aktuellen Systemzustandes.\\

\noindent
Alle selbst erstellten Anwendungsprogramme, Konfigurationsdateien und die Dokumentation dieser Thesis sollen als Open-Source Projekte in einem öffentlichen Repository zugänglich sein. Aus fachlicher Sicht ist es gerade in der Forensik sehr wichtig dem Nutzer die Möglichkeit zu geben, den Quellcode der Analyseprogramme einsehen zu können und notfalls auf spezielle Bedürfnisse anzupassen. Darüber hinaus kann die Datenverarbeitung transparent nachvollzogen werden.
Daher werden die einzelne Projekte mithilfe eines Git-Clients auf GitHub versioniert.\\
Nachfolgende Auflistung zeigt die Aufteilung der Projekte:
\begin{itemize}
\item Das Projekt \textit{foam-thesis}\footnote{Die Abkürzung \textit{foam} oder auch \textit{foAm} steht für \textit{\textbf{fo}rensische \textbf{A}nalyseplattfor\textbf{m}}} enthält die schriftliche Ausarbeitung der Thesis und den Quellcode als Latex-Projekt. Als Entwicklungsumgebung wird \textit{Texmaker} genutzt.\\
Über den Link \url{https://github.com/jobusam/foam-thesis} ist der aktuelle Stand der Arbeit jederzeit einsehbar.\footnote{Das kompilierte PDF-Dokument zum jeweiligen Stand wird im gleichen Projekt versioniert und ist unter dem Link \url{https://github.com/jobusam/foam-thesis/blob/master/main.pdf} verfügbar.}

\item Das Projekt \textit{foam-processing-spark} enthält den Quellcode zur Auswertung mit Apache Spark\texttrademark\thinspace. Unter \url{https://github.com/jobusam/foam-processing-spark} befindet sich ein Maven-Projekt, welches wiederum die Java-Anwendung baut. Es werden auch entsprechende Skripte zum Starten von Spark-Anwendungen auf dem lokalen Rechner bereitgestellt. 


\item Das Projekt \textit{foam-storage-hadoop} enthält alle Konfigurationsdateien zum Aufsetzten eines Hadoop-Cluster auf einem einzelnem Knoten im \textit{Pseudo-Distributed Mode}.\footnote{Siehe \url{https://github.com/jobusam/foam-storage-hadoop/tree/master/hadoop.standalone.configuration}} Zusätzlich existieren Shell-Skripte zum Starten des Hadoop-Clusters auf einem einzelnen Knoten.\footnote{Siehe \url{https://github.com/jobusam/foam-storage-hadoop/tree/master/hadoop.standalone.setup}} Das Hadoop-Cluster besteht nur aus dem HDFS und dem Resourcenmanager YARN. Mithilfe der Skripte aus dem \textit{foam-processing-spark} Projekt können damit Spark-Anwendungen auf einem lokalen Knoten innerhalb eines HDFS mit YARN ausgeführt werden.
\end{itemize}

\noindent
Derzeit ist die Lizenzierung beider Projekte noch nicht klar. Sehr wahrscheinlich wird die Thesis-Dokumentation unter der \textit{GNU Free Documentation License (GFDL)} lizenziert, wohingegen der restliche Quellcode unter der \textit{GNU Affero General Public License Version 3 (AGPLv3)} oder alternativ unter der Apache License 2.0 veröffentlicht werden soll. Es soll jedem möglich sein, den Quellcode einzusehen und nach belieben ändern zu können.\\

\noindent
Aus organisatorischen Gründen, wird darauf geachtet, dass während der Ausarbeitungszeit der Thesis nur Änderung von dem Autor selbst in dem entsprechenden Repository gehostet werden.\\

\section{Testdatengenerierung}
\label{testdatacreation}
\textbf{TODO: Kapitel überarbeiten...}
Für den Aufbau einer forensischen Analyseplattform sollen entsprechende Testdaten generiert werden. Hierbei gibt es zwei unterschiedliche Falldaten. Der erste Fall wäre ein kleines Image kleiner 10 GB. Dieses Image könnte für lokale Tests genutzt werden.\\
Im zweiten Fall müssen größere Images erzeugt werden, um ein passendes Szenario für das Hadoop Test-Cluster zu erzeugen. Der zweite Fall könnte 2 PCs und ein Server enthalten. Die Images der PCs sollten mindestens 100 GB groß sein, wohin gegen der Server 250 GB groß sein könnte. Ein zusätzlicher USB-Stick mit 64 GB Daten könnte auch dazu passen. Die Images dieser PCs und des Servers könnten virtualisiert erstellt werden. Folgende Applikationen könnten genutzt werden: Thunderbird, Firefox, Owncload, Apache HTTP Server. Es soll herausgefunden werden, wann welche Daten zwischen den drei Rechnern ausgetauscht wurden.\\

\noindent
Für lokale Tests und den Aufbau der Plattform bietet sich beispielsweise auch das Testscenario \textit{Data Leakage Case} an, welches auf der Website \textit{Computer Forensic Reference Data Sets} verfügbar ist.\footnote{Siehe \url{https://www.cfreds.nist.gov/data_leakage_case/data-leakage-case.html},\\ letzter Stand 28.3.2018.} \\
Diese Images könnten auf verdächtige Querverweise untersucht werden.