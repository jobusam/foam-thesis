% Kurzfassung, Abstract
%
\section*{Kurzfassung}
%Deutsch
Die digitale Forensik ist heutzutage ein wichtiger Teil bei der Aufklärung von Straftaten durch Ermittlungsbehörden. Nahezu in jedem Fall können digitale Beweismittel sichergestellt werden, weil informationstechnische Systeme im Alltag allgegenwärtig sind. Durch den rasanten Fortschritt von IT-Technologien, müssen auch die forensischen Methoden immer wieder neu adaptiert und verbessert werden. Allein die Datenmenge, welche aufgrund sichergestellter Mobiltelefone, Computer, Netzwerkspeicher und Server verarbeitet werden muss, kann durchaus mehrere Terabyte groß sein.\\
Um solche Datenmengen schnell und effizient bearbeiten zu können, wird in dieser Thesis eine forensische Analyseplattform entwickelt. Sie soll anfallende Daten verteilt in einem Computer-Cluster speichern und aufbereiten können. Zuerst soll geprüft werden, wie diese Daten verteilt gespeichert werden können. Im nächsten Schritt sollen neue Informationen aus dem gespeicherten Datenbestand extrahiert werden. Hierbei sollen auch forensische Aspekte, wie beispielsweise die Erstellung einer Beweismittelkette und die Sicherheit des Computer-Clusters, betrachtet werden.\\

\noindent
Zur Datenspeicherung wird das Apache Hadoop\textsuperscript{\textregistered}-Ökosystem genutzt. Es werden diverse Datenträgerabbilder erstellt, die als Grundlage zur Datenverarbeitung der Analyseplattform dienen sollen. Diese Abbilder können nicht ohne vorherige Datenaufbereitung in die Analyseplattform importiert werden, da sonst keine parallele Verarbeitung möglich wäre. Daher werden unterschiedliche Ansätze analysiert, wie diese Daten optimal im Hadoop-Cluster gespeichert werden können. In einer Variante werden die Daten auf logischer Dateiebene, Datei für Datei, in die Analyseplattform importiert. Dieser Ansatz ermöglicht eine parallele Datenverarbeitung. Allerdings können die Dateimetadaten nicht optimal gespeichert werden, was sich bei großen Datenmengen negativ auf die Geschwindigkeit der Datenverarbeitung auswirkt.
Die finale Variante zur Datenspeicherung ist eine Mischung aus zwei Datenspeicherarten. So werden die Dateimetadaten und kleine Dateien in einer spaltenorientierten Datenbank gespeichert. Wohingegen große Dateien im verteilten Dateisystem der Hadoop-Plattform abgelegt werden. Damit ist es auch möglich, die bestehenden Daten aus der Datenbank mit neuen Informationen aus der Datenverarbeitung anzureichern.\\

\noindent
Bei der Datenverarbeitung wird Apache Spark\texttrademark\thinspace genutzt, welches die Daten auf der Hadoop-Plattform parallel prozessieren kann. Es werden beispielsweise Hashsummen berechnet und Medientypen ermittelt.\\
Ein weiterer Aspekt ist die Implementierung einer Volltextsuche für einen performanten Datenzugriff. Hierzu werden die Daten im Computer-Cluster verteilt indexiert, um sie schneller durchsuchen zu können. Derzeit können nur die Dateimetadaten indexiert werden. Eine Indexierung aller Dateiinhalte kann in einer Weiterentwicklung des Systems implementiert werden.\\

\noindent
Letztlich ist es möglich, beliebige Datenträger mit der hier entwickelten forensischen Analyseplattform zu verarbeiten. Auch ein performanter Zugriff auf die Daten ist realisierbar. Allerdings hat diese Plattform auch Schwächen, welche zukünftig behoben werden sollten. So benötigt schon das Importieren großer Datenträger sehr viel Zeit. Hier wäre es sinnvoll, die Datenverarbeitung so umzustellen, dass einzelne Daten sofort prozessiert und angezeigt werden, um damit schon auf Teilergebnisse zugreifen zu können.


\newpage
\section*{Abstract}
%English
Digital forensics is an important part to resolve crime. Digital evidence may be found at almost every crime scene because information technology is pervasive. Apart from that, the forensic approach must be adapted and improved continuously. Merely the amount of data, collected from mobile phones, computers and network storages, can be very large (up to multiple tera bytes).\\

\noindent
A new forensic analysis platform shall be developed in this thesis to handle such a huge amount of data as quickly as possible. Therefore the data shall be stored on multiple nodes within a computer cluster to speed up the data processing by parallelism. The first part of this work handles the persistence of the data within the computer cluster. The next step is to find suitable approaches for processing the data and extracting new information out of them. Also these new information must be stored in a technically correct manner. Cross-cutting concerns, like the creation of a chain of custody and the computer cluster security, shall be handled also in this work.\\

\noindent
The forensic analysis platform will be based on the big data framework Apache Hadoop\textsuperscript{\textregistered}. During the development of this platform several disk images will be created, that can be used for testing. These disk images can be very large and must be preprocessed before saving it on the analysis platform. Otherwise the data processing engine can't process the data parallelly. There are several approaches how to save the data in a suitable manner on the cluster. 
In the first approach the data, saved on disk images, will be imported file by file. With this approach the data processing engine can be executed in parallel because the files can be analysed independently from each other. On the downside, the file metadata will be saved in a way that doesn't allow parallelized data processing. To solve this issue the finally introduced approach for data persistence contains a mixture of two different data storage types. The metadata of all imported files will be stored on a column-oriented database. Additionally the file content of small files will be also saved on this database. Whereas large files will be saved on the distributed file system of Hadoop. With this approach it's also possible to persist new information, extracted by the data processing engine, directly on the database.\\

\noindent
The open-source data analytics cluster computing framework Apache Spark\texttrademark\thinspace will be used as data processing engine. Based on this engine some simple data processing jobs will be implemented, like calculating file hashes and extracting file media types based on the file content.\\
In addition, a full text search will be implemented to support an easy access to the metadata. To get the extracted metadata quickly, it will be indexed by an enterprise search platform. Currently it's only possible to access the file metadata in this way. In future it shall be also possible to index the file contents to allow a real full text search on every persisted data.\\

\noindent
The results of this work approve the feasability to do forensic data analysis with the Apache Hadoop framework on large data sets. The data can be also accessed efficiently. Nevertheless there are some weaknesses that must be improved in future. The primary disadvantage of this analysis platform belongs to the time-consuming data import. To improve this performance issue, the data should be processed directly after saving it. With this approach the user can already analyse partial results while the data import is ongoing.  

\newpage

\section*{Danksagung}




\newpage

\section*{Eidesstattliche Erklärung}

Hiermit versichere ich an Eides statt, dass ich die vorliegende Arbeit selbstständig und
ohne Verwendung anderer als der angegebenen Hilfsmittel angefertigt habe. Alle Stellen,
die wörtlich oder sinngemäß aus veröffentlichten und nicht veröffentlichten Schriften
entnommen sind, sind als solche kenntlich gemacht. Die Arbeit hat in gleicher oder
ähnlicher Form noch in keiner anderen Prüfungsbehörde vorgelegen. Alle eingereichten
Versionen der Arbeit sind identisch.\\
\newline
\noindent
Meersburg, den 10.10.2018 \\
\vspace{1.5cm} \\
Johannes Busam\newline

\newpage
